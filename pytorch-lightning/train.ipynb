{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "ROOT_DIR = Path(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "BASE_DIR = ROOT_DIR / \"pytorch-lightning\"\n",
    "sys.path.append(ROOT_DIR)\n",
    "sys.path.append(BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytorch_lightning.trainer.connectors.checkpoint_connector as module_to_edit\n",
    "# !code {module_to_edit.__file__}\n",
    "# https://github.com/pytorch/pytorch/issues/80809#issuecomment-1173949444"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yezy/.conda/envs/yzy/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Callable, Dict, Optional, Tuple\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.strategies import *\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from data import LitDataModule\n",
    "from model import LitModule\n",
    "\n",
    "def train(\n",
    "    cfg,\n",
    "    fold: int,\n",
    "    data_frame: pd.DataFrame,\n",
    ") -> None:\n",
    "    pl.seed_everything(cfg.seed)\n",
    "\n",
    "    data_module = LitDataModule(\n",
    "        val_fold=fold,\n",
    "        data_frame=data_frame,\n",
    "        spatial_size=cfg.data.spatial_size,\n",
    "        batch_size=cfg.data.batch_size,\n",
    "        num_workers=cfg.data.num_workers,\n",
    "    )\n",
    "\n",
    "    data_module.setup()\n",
    "\n",
    "    module = LitModule(cfg)\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(cfg.train.checkpoint_dir,\n",
    "                                        monitor=\"val_dice_th\",\n",
    "                                        mode=\"max\",\n",
    "                                        verbose=True,\n",
    "                                        filename=f\"{module.model.__class__.__name__}_{cfg.model.backbone}_{cfg.data.spatial_size}_{fold}\",\n",
    "                                        )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        default_root_dir=cfg.train.checkpoint_dir,\n",
    "        accelerator=cfg.train.accelerator, \n",
    "        devices=cfg.train.devices,\n",
    "        strategy=DDPStrategy(find_unused_parameters=False) if cfg.train.strategy == \"DDP\" else cfg.train.strategy,\n",
    "        benchmark=True,\n",
    "        deterministic=False,\n",
    "        callbacks=[model_checkpoint],\n",
    "        limit_train_batches=1.0,\n",
    "        limit_val_batches=1.0,\n",
    "        log_every_n_steps=5,\n",
    "        logger=WandbLogger(name=f\"{module.model.__class__.__name__}_{cfg.model.backbone}_{cfg.data.spatial_size}_{fold}\", project=cfg.logger.wandb.project) if cfg.logger.wandb.use == True else False,\n",
    "        max_epochs=cfg.train.epochs,\n",
    "        precision=cfg.train.precision,\n",
    "        accumulate_grad_batches=cfg.data.accumulate_grad_batches,\n",
    "    )\n",
    "\n",
    "    trainer.tune(module, datamodule=data_module)\n",
    "\n",
    "    trainer.fit(module, datamodule=data_module, ckpt_path=os.path.join(os.getcwd(), cfg.train.checkpoint_dir, f\"{module.model.__class__.__name__}_{cfg.model.backbone}_{cfg.data.spatial_size}_{fold}\"+\".ckpt\") if os.path.exists(os.path.join(os.getcwd(), cfg.train.checkpoint_dir, f\"{module.model.__class__.__name__}_{cfg.model.backbone}_{cfg.data.spatial_size}_{fold}\"+\".ckpt\")) else None)\n",
    "    \n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = BASE_DIR / \"input\"\n",
    "OUTPUT_DIR = ROOT_DIR / \"working\"\n",
    "CONFIG_DIR = BASE_DIR / \"config\"\n",
    "\n",
    "COMPETITION_DATA_DIR = INPUT_DIR / \"hubmap-organ-segmentation\"\n",
    "CROPPED_DATA_DIR = INPUT_DIR / \"mmsegmentation512x512\"\n",
    "\n",
    "CONFIG_YAML_PATH = CONFIG_DIR / \"default.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from utils import EasyConfig\n",
    "\n",
    "cfg = EasyConfig()\n",
    "cfg.load(CONFIG_YAML_PATH)\n",
    "\n",
    "cfg_train = cfg.train\n",
    "cfg_data = cfg.data\n",
    "cfg_model = cfg.model\n",
    "\n",
    "file_list = np.unique([os.path.basename(i).split(\".\")[0] for i in glob.glob(str(CROPPED_DATA_DIR)+\"/*/*\")])\n",
    "kf = KFold(cfg_data.n_split, shuffle=True, random_state=cfg.seed)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"image\"] = glob.glob(str(CROPPED_DATA_DIR)+\"/train/*\")\n",
    "df[\"mask\"] = glob.glob(str(CROPPED_DATA_DIR)+\"/masks/*\")\n",
    "for fold, (_, val_idx) in enumerate(kf.split(file_list)):\n",
    "        df.loc[val_idx, \"fold\"] = fold\n",
    "df.to_csv(os.path.join(str(CROPPED_DATA_DIR), \"train.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mziyangye\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/yezy/HPA/pytorch-lightning/wandb/run-20220824_141019-2plq31zr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ziyangye/hubmap-organ-segmentation/runs/2plq31zr\" target=\"_blank\">UnetPlusPlus_with_ASPP_FPN_efficientnet-b4_512_0</a></strong> to <a href=\"https://wandb.ai/ziyangye/hubmap-organ-segmentation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "`Trainer(strategy='ddp')` is not compatible with an interactive environment. Run your code as a script, or choose one of the compatible strategies: Trainer(strategy=None|dp|tpu_spawn|ddp_fork). In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m/home/yezy/HPA/pytorch-lightning/train.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgc\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m fold \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(cfg_data\u001b[39m.\u001b[39mn_split):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     trainer \u001b[39m=\u001b[39m train(cfg, fold, df)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     wandb\u001b[39m.\u001b[39mfinish()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mdel\u001b[39;00m trainer\n",
      "\u001b[1;32m/home/yezy/HPA/pytorch-lightning/train.ipynb Cell 7\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cfg, fold, data_frame)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m module \u001b[39m=\u001b[39m LitModule(cfg)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m model_checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(cfg\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mcheckpoint_dir,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m                                     monitor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_dice_th\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m                                     mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m                                     verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m                                     filename\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodule\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mcfg\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mbackbone\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mcfg\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mspatial_size\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m                                     )\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39;49mTrainer(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m     default_root_dir\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mtrain\u001b[39m.\u001b[39;49mcheckpoint_dir,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m     accelerator\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mtrain\u001b[39m.\u001b[39;49maccelerator, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m     devices\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mtrain\u001b[39m.\u001b[39;49mdevices,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     strategy\u001b[39m=\u001b[39;49mDDPStrategy(find_unused_parameters\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m) \u001b[39mif\u001b[39;49;00m cfg\u001b[39m.\u001b[39;49mtrain\u001b[39m.\u001b[39;49mstrategy \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mDDP\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39melse\u001b[39;49;00m cfg\u001b[39m.\u001b[39;49mtrain\u001b[39m.\u001b[39;49mstrategy,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m     benchmark\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m     deterministic\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[model_checkpoint],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m     limit_train_batches\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m     limit_val_batches\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m     log_every_n_steps\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m     logger\u001b[39m=\u001b[39;49mWandbLogger(name\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodule\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mcfg\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mbackbone\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mcfg\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mspatial_size\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mfold\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, project\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mlogger\u001b[39m.\u001b[39;49mwandb\u001b[39m.\u001b[39;49mproject) \u001b[39mif\u001b[39;49;00m cfg\u001b[39m.\u001b[39;49mlogger\u001b[39m.\u001b[39;49mwandb\u001b[39m.\u001b[39;49muse \u001b[39m==\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m     max_epochs\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mtrain\u001b[39m.\u001b[39;49mepochs,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m     precision\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mtrain\u001b[39m.\u001b[39;49mprecision,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m     accumulate_grad_batches\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49maccumulate_grad_batches,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m trainer\u001b[39m.\u001b[39mtune(module, datamodule\u001b[39m=\u001b[39mdata_module)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.0.89/home/yezy/HPA/pytorch-lightning/train.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m trainer\u001b[39m.\u001b[39mfit(module, datamodule\u001b[39m=\u001b[39mdata_module, ckpt_path\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mgetcwd(), cfg\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mcheckpoint_dir, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodule\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mcfg\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mbackbone\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mcfg\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mspatial_size\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.ckpt\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mgetcwd(), cfg\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mcheckpoint_dir, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodule\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mcfg\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mbackbone\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mcfg\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mspatial_size\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.ckpt\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/yzy/lib/python3.8/site-packages/pytorch_lightning/utilities/argparse.py:345\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mlist\u001b[39m(env_variables\u001b[39m.\u001b[39mitems()) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mitems()))\n\u001b[1;32m    344\u001b[0m \u001b[39m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m--> 345\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/yzy/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:433\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, logger, enable_checkpointing, callbacks, default_root_dir, gradient_clip_val, gradient_clip_algorithm, num_nodes, num_processes, devices, gpus, auto_select_gpus, tpu_cores, ipus, enable_progress_bar, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, val_check_interval, log_every_n_steps, accelerator, strategy, sync_batchnorm, precision, enable_model_summary, weights_save_path, num_sanity_val_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_n_epochs, auto_lr_find, replace_sampler_ddp, detect_anomaly, auto_scale_batch_size, plugins, amp_backend, amp_level, move_metrics_to_cpu, multiple_trainloader_mode)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[39m# init connectors\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector \u001b[39m=\u001b[39m DataConnector(\u001b[39mself\u001b[39m, multiple_trainloader_mode)\n\u001b[0;32m--> 433\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_connector \u001b[39m=\u001b[39m AcceleratorConnector(\n\u001b[1;32m    434\u001b[0m     num_processes\u001b[39m=\u001b[39;49mnum_processes,\n\u001b[1;32m    435\u001b[0m     devices\u001b[39m=\u001b[39;49mdevices,\n\u001b[1;32m    436\u001b[0m     tpu_cores\u001b[39m=\u001b[39;49mtpu_cores,\n\u001b[1;32m    437\u001b[0m     ipus\u001b[39m=\u001b[39;49mipus,\n\u001b[1;32m    438\u001b[0m     accelerator\u001b[39m=\u001b[39;49maccelerator,\n\u001b[1;32m    439\u001b[0m     strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[1;32m    440\u001b[0m     gpus\u001b[39m=\u001b[39;49mgpus,\n\u001b[1;32m    441\u001b[0m     num_nodes\u001b[39m=\u001b[39;49mnum_nodes,\n\u001b[1;32m    442\u001b[0m     sync_batchnorm\u001b[39m=\u001b[39;49msync_batchnorm,\n\u001b[1;32m    443\u001b[0m     benchmark\u001b[39m=\u001b[39;49mbenchmark,\n\u001b[1;32m    444\u001b[0m     replace_sampler_ddp\u001b[39m=\u001b[39;49mreplace_sampler_ddp,\n\u001b[1;32m    445\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m    446\u001b[0m     auto_select_gpus\u001b[39m=\u001b[39;49mauto_select_gpus,\n\u001b[1;32m    447\u001b[0m     precision\u001b[39m=\u001b[39;49mprecision,\n\u001b[1;32m    448\u001b[0m     amp_type\u001b[39m=\u001b[39;49mamp_backend,\n\u001b[1;32m    449\u001b[0m     amp_level\u001b[39m=\u001b[39;49mamp_level,\n\u001b[1;32m    450\u001b[0m     plugins\u001b[39m=\u001b[39;49mplugins,\n\u001b[1;32m    451\u001b[0m )\n\u001b[1;32m    452\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger_connector \u001b[39m=\u001b[39m LoggerConnector(\u001b[39mself\u001b[39m)\n\u001b[1;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_connector \u001b[39m=\u001b[39m CallbackConnector(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/yzy/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:228\u001b[0m, in \u001b[0;36mAcceleratorConnector.__init__\u001b[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, amp_type, amp_level, sync_batchnorm, benchmark, replace_sampler_ddp, deterministic, auto_select_gpus, num_processes, tpu_cores, ipus, gpus)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_and_init_precision()\n\u001b[1;32m    227\u001b[0m \u001b[39m# 6. Instantiate Strategy - Part 2\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lazy_init_strategy()\n",
      "File \u001b[0;32m~/.conda/envs/yzy/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:809\u001b[0m, in \u001b[0;36mAcceleratorConnector._lazy_init_strategy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m \u001b[39mimport\u001b[39;00m _IS_INTERACTIVE\n\u001b[1;32m    808\u001b[0m \u001b[39mif\u001b[39;00m _IS_INTERACTIVE \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mis_interactive_compatible:\n\u001b[0;32m--> 809\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m    810\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`Trainer(strategy=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mstrategy_name\u001b[39m!r}\u001b[39;00m\u001b[39m)` is not compatible with an interactive\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    811\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m environment. Run your code as a script, or choose one of the compatible strategies:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    812\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Trainer(strategy=None|\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m|\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(_StrategyType\u001b[39m.\u001b[39minteractive_compatible_types())\u001b[39m}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    813\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m In case you are spawning processes yourself, make sure to include the Trainer\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    814\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m creation inside the worker function.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    815\u001b[0m     )\n\u001b[1;32m    817\u001b[0m \u001b[39m# TODO: should be moved to _check_strategy_and_fallback().\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[39m# Current test check precision first, so keep this check here to meet error order\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator, TPUAccelerator) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    820\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy, (SingleTPUStrategy, TPUSpawnStrategy)\n\u001b[1;32m    821\u001b[0m ):\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: `Trainer(strategy='ddp')` is not compatible with an interactive environment. Run your code as a script, or choose one of the compatible strategies: Trainer(strategy=None|dp|tpu_spawn|ddp_fork). In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function."
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import gc\n",
    "for fold in range(cfg_data.n_split):\n",
    "    trainer = train(cfg, fold, df)\n",
    "    wandb.finish()\n",
    "    del trainer\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('yzy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f91abce07d273583bd7a75d5496090b46b21fc7508d2a3384552f28a6b2401e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
